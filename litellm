COPY ./opt/litellm/litellm.yaml /opt/litellm/litellm.yaml
COPY ./opt/litellm/hooks/pdf_hook.py /opt/litellm/hooks/pdf_hook.py

# Optional: set defaults for the hook via env (overridable in Deployment)
ENV PDF_FILESIZE_LIMIT_MB=20 \
    PDF_MAX_PAGES=25 \
    PDF_OCR_MAX_PAGES=5 \
    PDF_TOKEN_BUDGET=6000 \
    PDF_USE_EASYOCR=1

---- /opt/litellm/hooks/pdf_hook.py---

import os, re, io, base64
from typing import Any, Dict, List, Optional

# Register hook with LiteLLM proxy (no-op if not present at import)
try:
    from litellm.proxy._hooks import add_async_pre_call_hook
except Exception:
    def add_async_pre_call_hook(_):  # no-op
        pass

# Lazy imports so startup never fails if a dep is missing
def _mods():
    import importlib
    m = {}
    for name in ("pdfplumber", "fitz", "easyocr", "numpy"):
        try:
            m[name] = importlib.import_module(name if name != "fitz" else "fitz")
        except Exception:
            m[name] = None
    return m

PDF_DATA_PREFIX = "data:application/pdf;base64,"
PDF_MAX_MB = float(os.environ.get("PDF_FILESIZE_LIMIT_MB", "20"))
PDF_MAX_PAGES = int(os.environ.get("PDF_MAX_PAGES", "25"))
OCR_MAX_PAGES  = int(os.environ.get("PDF_OCR_MAX_PAGES", "5"))
TOKEN_BUDGET   = int(os.environ.get("PDF_TOKEN_BUDGET", "6000"))  # ~24k chars
USE_EASYOCR    = os.environ.get("PDF_USE_EASYOCR", "1") == "1"

def _collect_pdf_data_urls(messages: List[Dict[str, Any]]) -> Optional[Dict[str, str]]:
    # Returns {"filename": str, "data": str} for the first PDF found
    for msg in messages:
        content = msg.get("content")
        if isinstance(content, list):
            for part in content:
                if isinstance(part, dict) and part.get("type") == "file":
                    f = part.get("file") or {}
                    data = f.get("file_data")
                    if isinstance(data, str) and data.startswith(PDF_DATA_PREFIX):
                        return {"filename": f.get("filename") or "file.pdf", "data": data}
    return None

def _b64bytes(data_url: str) -> bytes:
    return base64.b64decode(data_url.split(",", 1)[1])

def _mb(nbytes: int) -> float:
    return nbytes / (1024 * 1024.0)

def _truncate(text: str, tokens: int) -> str:
    return text[: max(1, tokens) * 4]  # ~4 chars per token

def _clean(text: str) -> str:
    text = re.sub(r"[ \t]+", " ", text)
    text = re.sub(r"\n{3,}", "\n\n", text)
    return text.strip()

def _extract_pdfplumber(pdf_bytes: bytes, m) -> Optional[str]:
    pp = m.get("pdfplumber")
    if not pp: return None
    try:
        out, pages = [], 0
        with pp.open(io.BytesIO(pdf_bytes)) as pdf:
            for p in pdf.pages:
                if pages >= PDF_MAX_PAGES: break
                out.append(p.extract_text(x_tolerance=2, y_tolerance=2) or "")
                pages += 1
        text = "\n\n".join(out).strip()
        return _clean(text) if text else None
    except Exception:
        return None

def _extract_ocr(pdf_bytes: bytes, m) -> Optional[str]:
    # Pure-Python OCR fallback: render with PyMuPDF, OCR with EasyOCR (GPU if available)
    fitz, easyocr, np = m.get("fitz"), m.get("easyocr"), m.get("numpy")
    if not (fitz and easyocr and np): return None
    try:
        import numpy as np
        reader = easyocr.Reader(["en"], gpu=True)
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        out, pages = [], 0
        for page in doc:
            if pages >= OCR_MAX_PAGES: break
            pm = page.get_pixmap(alpha=False, dpi=200)
            arr = np.frombuffer(pm.samples, dtype=np.uint8).reshape(pm.height, pm.width, pm.n)
            lines = reader.readtext(arr, detail=0, paragraph=True)
            out.append("\n".join(lines))
            pages += 1
        text = "\n\n".join(out).strip()
        return _clean(text) if text else None
    except Exception:
        return None

def _inject(messages: List[Dict[str, Any]], text: str, label: str) -> List[Dict[str, Any]]:
    header = f"[Extracted from {label}]\n{text}"
    return [{"role": "system", "content": header}] + messages

async def pdf_preprocess_hook(model: str, messages: List[Dict[str, Any]], **kwargs):
    # Find base64 PDF only; no URLs (offline)
    found = _collect_pdf_data_urls(messages)
    if not found:
        return {}

    label = found["filename"]
    pdf_bytes = _b64bytes(found["data"])
    if _mb(len(pdf_bytes)) > PDF_MAX_MB:
        # Too big: inject a small notice and pass through
        note = f"[Note] Skipped PDF '{label}' â€“ size { _mb(len(pdf_bytes)):.1f}MB exceeds limit {PDF_MAX_MB}MB."
        return {"messages": [{"role":"system","content":note}] + messages}

    m = _mods()
    text = _extract_pdfplumber(pdf_bytes, m)
    if (not text) and USE_EASYOCR:
        text = _extract_ocr(pdf_bytes, m)
    if not text:
        return {}  # pass-through if we got nothing

    text = _truncate(text, TOKEN_BUDGET)
    new_messages = _inject(messages, text, label)
    return {"messages": new_messages}

# Register on import
add_async_pre_call_hook(pdf_preprocess_hook)

---
/opt/litellm/litellm.yaml
litellm config

model_list:
  - model_name: llama-4-scout
    litellm_params:
      model: llama-4-scout-17b-16e
      api_base: http://127.0.0.1:8010

---

start-script via configmap

#!/bin/bash
# Dependency checks
if [ ! -d "/weights/llama4" ]; then echo "Error: /weights/llama4 missing"; exit 1; fi

# Start vLLM (handles text + vision)
python3 -m vllm.entrypoints.openai.api_server \
  --model /weights/llama4 \
  --served-model-name llama-4-scout-17b-16e \
  --host 127.0.0.1 --port 8010 \
  --tensor-parallel-size 4 \
  --dtype auto \
  --gpu-memory-utilization 0.90 \
  --max-model-len 8192 \
  --trust-remote-code true \
  --limit-mm-per-prompt image=5 \
  --max-num-batched-tokens 32768 \
  --max-num-seqs 64 &

# Wait for vLLM health
for i in {1..30}; do
  if curl -s http://127.0.0.1:8010/v1/models > /dev/null; then
    echo "vLLM ready"
    break
  fi
  if [ $i -eq 30 ]; then
    echo "Error: vLLM not ready after 30 attempts"
    exit 1
  fi
  sleep 2
done

# Start LiteLLM
litellm --config /opt/litellm/litellm.yaml \
  --host 0.0.0.0 --port 9000 \
  --custom-logger /opt/litellm/hooks/pdf_hook.py

--


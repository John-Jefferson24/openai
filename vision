new pdf_proceeor
----------------------------

import os
import base64
from typing import Dict, List, Optional

# ===== CONFIG =====
PDF_DATA_PREFIX = "data:application/pdf;base64,"
PDF_MAX_MB = float(os.environ.get("PDF_FILESIZE_LIMIT_MB", "50"))
PDF_MAX_PAGES = int(os.environ.get("PDF_MAX_PAGES", "10"))  # Reduced for images
PDF_IMAGE_DPI = int(os.environ.get("PDF_IMAGE_DPI", "100"))  # Lower DPI for smaller images

# ===== LAZY IMPORTS =====
def _mods():
    import importlib
    m = {}
    for name in ("fitz",):  # Only need PyMuPDF
        try:
            m[name] = importlib.import_module(name)
        except Exception:
            m[name] = None
    return m

# ===== HELPERS =====
def _collect_pdf_data_urls(messages: List[Dict]) -> Optional[Dict[str, str]]:
    for msg in messages:
        content = msg.get("content")
        if isinstance(content, list):
            for part in content:
                if isinstance(part, dict) and part.get("type") == "file":
                    f = part.get("file") or {}
                    data = f.get("file_data")
                    if isinstance(data, str) and data.startswith(PDF_DATA_PREFIX):
                        return {"filename": f.get("filename") or "file.pdf", "data": data}
    return None

def _b64bytes(data_url: str) -> bytes:
    return base64.b64decode(data_url.split(",", 1)[1])

def _mb(nbytes: int) -> float:
    return nbytes / (1024 * 1024.0)

def _already_injected(messages: List[Dict]) -> bool:
    """Check if we already processed PDFs (look for our marker text)"""
    for msg in messages:
        content = msg.get("content")
        if isinstance(content, list):
            for part in content:
                if isinstance(part, dict) and part.get("type") == "text":
                    text = part.get("text", "")
                    if text.startswith("[PDF:") or text.startswith("[PDF Processing Error]"):
                        return True  # Found our marker
    return False

def _pdf_to_images(pdf_bytes: bytes, m) -> Optional[List[str]]:
    """Convert PDF pages to base64 PNG images"""
    fitz = m.get("fitz")
    if not fitz:
        return None
    
    try:
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        images = []
        
        for i, page in enumerate(doc):
            if i >= PDF_MAX_PAGES:
                break
            
            # Render page to image with lower DPI for reasonable size
            pix = page.get_pixmap(dpi=PDF_IMAGE_DPI)
            
            # Convert to JPEG for smaller size (PNG can be huge)
            img_bytes = pix.tobytes("jpeg", jpg_quality=85)
            
            # Check individual image size (skip if > 5MB)
            if len(img_bytes) > 5 * 1024 * 1024:
                print(f"Warning: Page {i+1} skipped - image too large ({len(img_bytes)/(1024*1024):.1f}MB)")
                continue
            
            img_b64 = base64.b64encode(img_bytes).decode('utf-8')
            images.append(f"data:image/jpeg;base64,{img_b64}")
        
        return images if images else None
    except Exception as e:
        print(f"PDF to image conversion failed: {e}")
        return None

def _replace_pdf_with_images(messages: List[Dict], images: List[str], label: str) -> List[Dict]:
    """Replace PDF file with image_url entries for vision model"""
    modified = []
    for msg in messages:
        content = msg.get("content")
        if isinstance(content, list):
            new_content = []
            for part in content:
                if isinstance(part, dict) and part.get("type") == "file":
                    # Add instruction text
                    new_content.append({
                        "type": "text",
                        "text": f"[PDF: {label} - {len(images)} page(s)]"
                    })
                    # Add each page as image
                    for idx, img_data in enumerate(images):
                        new_content.append({
                            "type": "image_url",
                            "image_url": {"url": img_data}
                        })
                else:
                    new_content.append(part)
            modified.append({**msg, "content": new_content})
        else:
            modified.append(msg)
    return modified

def _inject_error(messages: List[Dict], error_msg: str) -> List[Dict]:
    """Replace PDF file with error message"""
    modified = []
    for msg in messages:
        content = msg.get("content")
        if isinstance(content, list):
            new_content = []
            for part in content:
                if isinstance(part, dict) and part.get("type") == "file":
                    new_content.append({
                        "type": "text",
                        "text": f"[PDF Processing Error] {error_msg}"
                    })
                else:
                    new_content.append(part)
            modified.append({**msg, "content": new_content})
        else:
            modified.append(msg)
    return modified

# ===== MAIN PROCESSOR =====
class PDFProcessor:
    def process_pdf(self, data: dict) -> dict:
        """Process PDF by converting to images for vision model"""
        messages = data.get("messages")
        if not isinstance(messages, list):
            return data
        
        if _already_injected(messages):
            return data

        found = _collect_pdf_data_urls(messages)
        if not found:
            return data

        label = found["filename"]
        pdf_bytes = _b64bytes(found["data"])

        if _mb(len(pdf_bytes)) > PDF_MAX_MB:
            note = f"Skipped PDF '{label}' – size {_mb(len(pdf_bytes)):.1f}MB exceeds limit {PDF_MAX_MB}MB."
            data["messages"] = _inject_error(messages, note)
            return data

        m = _mods()
        if not m.get("fitz"):
            error_msg = f"Cannot process '{label}'. Missing pymupdf library (pip install pymupdf)."
            data["messages"] = _inject_error(messages, error_msg)
            return data

        # Convert PDF pages to images
        images = _pdf_to_images(pdf_bytes, m)
        
        if not images:
            error_msg = f"Unable to convert '{label}' to images. PDF may be corrupted or empty."
            data["messages"] = _inject_error(messages, error_msg)
            return data

        # Replace PDF file with images
        data["messages"] = _replace_pdf_with_images(messages, images, label)
        return data

# Export singleton instance
pdf_processor = PDFProcessor()

---------------

new fastapi

-------------------------

import os
from fastapi import FastAPI, Request, Response
from fastapi.responses import StreamingResponse
import httpx
import asyncio

VLLM_URL = os.getenv("VLLM_URL", "http://localhost:8000").rstrip("/")
MAX_CONCURRENT_PDF = int(os.getenv("MAX_CONCURRENT_PDF", "5"))

app = FastAPI()

# DO NOT create semaphore at module level - must be created inside event loop
_pdf_semaphore = None

def get_pdf_semaphore():
    """Get or create semaphore for current event loop"""
    global _pdf_semaphore
    try:
        loop = asyncio.get_running_loop()
        if _pdf_semaphore is None:
            _pdf_semaphore = asyncio.Semaphore(MAX_CONCURRENT_PDF)
        return _pdf_semaphore
    except RuntimeError:
        # No event loop running
        return None

@app.api_route("/{path:path}", methods=["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS", "HEAD"])
async def proxy(request: Request, path: str):
    """Pass everything to vLLM as-is"""
    
    body = await request.body()
    
    # Only check for PDF if this looks like chat completions
    if body and "chat/completions" in path:
        try:
            import json
            data = json.loads(body)
            
            # Quick check: does any message have PDF file type?
            messages = data.get("messages", [])
            has_pdf = any(
                isinstance(msg.get("content"), list) and
                any(
                    part.get("type") == "file" and
                    str(part.get("file", {}).get("file_data", "")).startswith("data:application/pdf;base64,")
                    for part in msg["content"] if isinstance(part, dict)
                )
                for msg in messages if isinstance(msg, dict)
            )
            
            if has_pdf:
                # Limit concurrent PDF processing
                semaphore = get_pdf_semaphore()
                if semaphore:
                    async with semaphore:
                        from pdf_processor import pdf_processor
                        # PDF processing is CPU-intensive but synchronous
                        data = pdf_processor.process_pdf(data)
                        body = json.dumps(data).encode()
                else:
                    # No semaphore (shouldn't happen in FastAPI), process anyway
                    from pdf_processor import pdf_processor
                    data = pdf_processor.process_pdf(data)
                    body = json.dumps(data).encode()
        except:
            pass  # Any error, just pass original body through
    
    # Forward everything to vLLM
    url = f"{VLLM_URL}/{path}"
    
    # Remove hop-by-hop headers (must not be forwarded per HTTP spec)
    hop_by_hop = {"host", "content-length", "transfer-encoding", "connection", 
                  "keep-alive", "te", "trailer", "upgrade", "proxy-authorization"}
    headers = {k: v for k, v in request.headers.items() if k.lower() not in hop_by_hop}
    
    # Check if streaming
    is_streaming = b'"stream":true' in body or b'"stream": true' in body
    
    if is_streaming:
        # Streaming response - keep client alive for entire stream
        client = httpx.AsyncClient(timeout=300.0)
        
        async def stream():
            try:
                async with client.stream(
                    method=request.method,
                    url=url,
                    headers=headers,
                    params=request.query_params,
                    content=body
                ) as resp:
                    async for chunk in resp.aiter_bytes():
                        yield chunk
            finally:
                await client.aclose()  # Always close client when done
        
        return StreamingResponse(stream(), media_type="text/event-stream")
    else:
        # Regular response
        async with httpx.AsyncClient(timeout=300.0) as client:
            resp = await client.request(
                method=request.method,
                url=url,
                headers=headers,
                params=request.query_params,
                content=body
            )
            
            return Response(
                content=resp.content,
                status_code=resp.status_code,
                headers=dict(resp.headers)
            )

if __name__ == "__main__":
    import uvicorn
      uvicorn.run(app, host="0.0.0.0", port=9000)

      -------------------
testinfg

"""
Complete test suite for OpenAI proxy with PDF processing
Tests: text, streaming, vision, PDF processing, multi-turn
Focused on financial documents (bank statements, reports, tables)
Questions range from EASY (summary) to HARD (complex extraction/analysis)
"""
import base64
import time
from pathlib import Path
from openai import OpenAI

# ===== CONFIGURATION =====
PROXY_URL = "http://localhost:8080/v1"
TEST_FILES_DIR = Path("C:/temp")
MODEL_NAME = "gpt-4-vision"  # Change this to your vLLM model name

# ===== CUSTOMIZABLE QUESTIONS =====
# Organized by difficulty: EASY → MEDIUM → HARD
QUESTIONS = {
    # EASY - Basic understanding and summary
    "pdf_easy_summary": "Summarize this financial document in 2-3 sentences.",
    "pdf_easy_type": "What type of financial document is this?",
    "image_easy_identify": "What kind of financial document is shown in this image?",
    
    # MEDIUM - Specific data extraction
    "pdf_medium_revenue": "What is the total revenue shown in this document?",
    "pdf_medium_year": "What year or time period does this financial statement cover?",
    "pdf_medium_table": "List the main categories or line items shown in any tables.",
    "image_medium_numbers": "Extract any dollar amounts or percentages visible in this image.",
    
    # HARD - Complex analysis and comparison
    "pdf_hard_specific_year": "What were the detailed financial results for 2010? Include revenue, expenses, and net income.",
    "pdf_hard_extract_table": "Extract all numerical data from the financial tables and present it in a structured format.",
    "pdf_hard_compare": "Compare financial performance across different years or quarters if multiple periods are shown.",
    "pdf_hard_calculate": "Calculate the profit margin or any financial ratios based on the numbers in this document.",
    
    # Multi-turn (progressive difficulty)
    "multi_turn_1": "What type of financial document is this?",
    "multi_turn_2": "What is the reporting period or date?",
    "multi_turn_3": "Extract the three most important financial metrics from this document.",
}

# Initialize client
client = OpenAI(
    base_url=PROXY_URL,
    api_key="dummy"  # vLLM doesn't require key by default
)

def encode_image(image_path):
    """Convert image to base64 data URL"""
    with open(image_path, "rb") as f:
        img_data = base64.b64encode(f.read()).decode('utf-8')
    
    # Detect format
    ext = image_path.suffix.lower()
    mime_type = {
        '.jpg': 'image/jpeg',
        '.jpeg': 'image/jpeg',
        '.png': 'image/png',
        '.gif': 'image/gif',
        '.webp': 'image/webp'
    }.get(ext, 'image/jpeg')
    
    return f"data:{mime_type};base64,{img_data}"

def encode_pdf(pdf_path):
    """Convert PDF to base64 data URL"""
    with open(pdf_path, "rb") as f:
        pdf_data = base64.b64encode(f.read()).decode('utf-8')
    return f"data:application/pdf;base64,{pdf_data}"

def test_1_simple_text():
    """Test 1: Simple text completion (baseline)"""
    print("\n" + "="*60)
    print("TEST 1: Simple Text Completion (Baseline)")
    print("="*60)
    
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "user", "content": "Say 'Hello World' and nothing else"}
            ],
            max_tokens=50
        )
        
        result = response.choices[0].message.content
        print(f"✓ Response: {result}")
        print(f"✓ Model: {MODEL_NAME}")
        print(f"✓ Tokens used: {response.usage.total_tokens}")
        return True
    except Exception as e:
        print(f"✗ Error: {e}")
        return False

def test_2_streaming_text():
    """Test 2: Streaming text completion (baseline)"""
    print("\n" + "="*60)
    print("TEST 2: Streaming Text (Baseline)")
    print("="*60)
    
    try:
        stream = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "user", "content": "Count from 1 to 5"}
            ],
            stream=True,
            max_tokens=50
        )
        
        print("✓ Streaming response: ", end="", flush=True)
        full_response = ""
        for chunk in stream:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                print(content, end="", flush=True)
                full_response += content
        
        print(f"\n✓ Full response: {full_response.strip()}")
        return True
    except Exception as e:
        print(f"✗ Error: {e}")
        return False

def test_3_vision_single_image():
    """Test 3: Vision - EASY (identify document type)"""
    print("\n" + "="*60)
    print("TEST 3: Vision - EASY (Identify Document)")
    print("="*60)
    
    # Look for an image in C:/temp
    image_files = list(TEST_FILES_DIR.glob("*.jpg")) + list(TEST_FILES_DIR.glob("*.png"))
    
    if not image_files:
        print("✗ No image files found in C:/temp (looking for .jpg or .png)")
        print("  Please add a financial document image to C:/temp/")
        print("  (e.g., bank statement, invoice, financial report)")
        return False
    
    image_path = image_files[0]
    print(f"Using image: {image_path.name}")
    print(f"Question (EASY): {QUESTIONS['image_easy_identify']}")
    
    try:
        image_data = encode_image(image_path)
        
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": QUESTIONS['image_easy_identify']},
                        {"type": "image_url", "image_url": {"url": image_data}}
                    ]
                }
            ],
            max_tokens=100
        )
        
        result = response.choices[0].message.content
        print(f"✓ Response: {result}")
        return True
    except Exception as e:
        print(f"✗ Error: {e}")
        return False

def test_4_vision_multi_turn():
    """Test 4: Vision - Progressive Difficulty (EASY → MEDIUM → HARD)"""
    print("\n" + "="*60)
    print("TEST 4: Vision - Multi-turn (Progressive Difficulty)")
    print("="*60)
    
    image_files = list(TEST_FILES_DIR.glob("*.jpg")) + list(TEST_FILES_DIR.glob("*.png"))
    
    if not image_files:
        print("✗ No image files found in C:/temp")
        return False
    
    image_path = image_files[0]
    print(f"Using image: {image_path.name}")
    
    try:
        image_data = encode_image(image_path)
        
        # Turn 1: EASY - Identify document
        print(f"\n[EASY] Turn 1: {QUESTIONS['multi_turn_1']}")
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": QUESTIONS['multi_turn_1']},
                    {"type": "image_url", "image_url": {"url": image_data}}
                ]
            }
        ]
        
        response1 = client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            max_tokens=100
        )
        
        result1 = response1.choices[0].message.content
        print(f"✓ Response: {result1}")
        
        # Turn 2: MEDIUM - Extract specific info
        print(f"\n[MEDIUM] Turn 2: {QUESTIONS['multi_turn_2']}")
        messages.append({"role": "assistant", "content": result1})
        messages.append({"role": "user", "content": QUESTIONS['multi_turn_2']})
        
        response2 = client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            max_tokens=100
        )
        
        result2 = response2.choices[0].message.content
        print(f"✓ Response: {result2}")
        
        # Turn 3: HARD - Extract key metrics
        print(f"\n[HARD] Turn 3: {QUESTIONS['multi_turn_3']}")
        messages.append({"role": "assistant", "content": result2})
        messages.append({"role": "user", "content": QUESTIONS['multi_turn_3']})
        
        response3 = client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            max_tokens=200
        )
        
        result3 = response3.choices[0].message.content
        print(f"✓ Response: {result3}")
        
        return True
    except Exception as e:
        print(f"✗ Error: {e}")
        return False

def test_5_pdf_processing():
    """Test 5: PDF - EASY (simple summary)"""
    print("\n" + "="*60)
    print("TEST 5: PDF - EASY (Summary)")
    print("="*60)
    
    pdf_files = list(TEST_FILES_DIR.glob("*.pdf"))
    
    if not pdf_files:
        print("✗ No PDF files found in C:/temp")
        print("  Please add a financial PDF to C:/temp/")
        print("  (e.g., bank statement, annual report, balance sheet)")
        return False
    
    pdf_path = pdf_files[0]
    print(f"Using PDF: {pdf_path.name}")
    print(f"Question (EASY): {QUESTIONS['pdf_easy_summary']}")
    
    try:
        pdf_data = encode_pdf(pdf_path)
        
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "file",
                            "file": {
                                "file_data": pdf_data,
                                "filename": pdf_path.name
                            }
                        },
                        {"type": "text", "text": QUESTIONS['pdf_easy_summary']}
                    ]
                }
            ],
            max_tokens=200
        )
        
        result = response.choices[0].message.content
        print(f"✓ Response: {result}")
        return True
    except Exception as e:
        print(f"✗ Error: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_6_pdf_streaming():
    """Test 6: PDF - MEDIUM (specific data extraction with streaming)"""
    print("\n" + "="*60)
    print("TEST 6: PDF - MEDIUM (Data Extraction + Streaming)")
    print("="*60)
    
    pdf_files = list(TEST_FILES_DIR.glob("*.pdf"))
    
    if not pdf_files:
        print("✗ No PDF files found in C:/temp")
        return False
    
    pdf_path = pdf_files[0]
    print(f"Using PDF: {pdf_path.name}")
    print(f"Question (MEDIUM): {QUESTIONS['pdf_medium_revenue']}")
    
    try:
        pdf_data = encode_pdf(pdf_path)
        
        stream = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "file",
                            "file": {
                                "file_data": pdf_data,
                                "filename": pdf_path.name
                            }
                        },
                        {"type": "text", "text": QUESTIONS['pdf_medium_revenue']}
                    ]
                }
            ],
            stream=True,
            max_tokens=200
        )
        
        print("✓ Streaming response: ", end="", flush=True)
        full_response = ""
        for chunk in stream:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                print(content, end="", flush=True)
                full_response += content
        
        print(f"\n✓ Complete response received ({len(full_response)} chars)")
        return True
    except Exception as e:
        print(f"✗ Error: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_7_pdf_table_extraction():
    """Test 7: PDF - HARD (complex table extraction)"""
    print("\n" + "="*60)
    print("TEST 7: PDF - HARD (Table Data Extraction)")
    print("="*60)
    
    pdf_files = list(TEST_FILES_DIR.glob("*.pdf"))
    
    if not pdf_files:
        print("✗ No PDF files found in C:/temp")
        return False
    
    pdf_path = pdf_files[0]
    print(f"Using PDF: {pdf_path.name}")
    print(f"Question (HARD): {QUESTIONS['pdf_hard_extract_table']}")
    
    try:
        pdf_data = encode_pdf(pdf_path)
        
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "file",
                            "file": {
                                "file_data": pdf_data,
                                "filename": pdf_path.name
                            }
                        },
                        {"type": "text", "text": QUESTIONS['pdf_hard_extract_table']}
                    ]
                }
            ],
            max_tokens=500
        )
        
        result = response.choices[0].message.content
        print(f"✓ Response: {result}")
        return True
    except Exception as e:
        print(f"✗ Error: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_8_pdf_year_specific():
    """Test 8: PDF - HARD (year-specific detailed analysis)"""
    print("\n" + "="*60)
    print("TEST 8: PDF - HARD (Year-Specific Analysis)")
    print("="*60)
    
    pdf_files = list(TEST_FILES_DIR.glob("*.pdf"))
    
    if not pdf_files:
        print("✗ No PDF files found in C:/temp")
        return False
    
    pdf_path = pdf_files[0]
    print(f"Using PDF: {pdf_path.name}")
    print(f"Question (HARD): {QUESTIONS['pdf_hard_specific_year']}")
    
    try:
        pdf_data = encode_pdf(pdf_path)
        
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "file",
                            "file": {
                                "file_data": pdf_data,
                                "filename": pdf_path.name
                            }
                        },
                        {"type": "text", "text": QUESTIONS['pdf_hard_specific_year']}
                    ]
                }
            ],
            max_tokens=400
        )
        
        result = response.choices[0].message.content
        print(f"✓ Response: {result}")
        return True
    except Exception as e:
        print(f"✗ Error: {e}")
        import traceback
        traceback.print_exc()
        return False"✗ Error: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """Run all tests"""
    print("\n" + "#"*60)
    print("# OPENAI PROXY TEST SUITE - FINANCIAL DOCUMENTS")
    print("# Proxy URL:", PROXY_URL)
    print("# Test Files:", TEST_FILES_DIR)
    print("#"*60)
    print("\n📋 Customizable Questions:")
    for key, question in QUESTIONS.items():
        print(f"  - {key}: {question[:60]}...")
    print("\n💡 Edit QUESTIONS dict at top of file to customize\n")
    
    tests = [
        ("Simple Text", test_1_simple_text),
        ("Streaming Text", test_2_streaming_text),
        ("Vision - Financial Image", test_3_vision_single_image),
        ("Vision - Multi-turn Financial", test_4_vision_multi_turn),
        ("PDF - Basic Financial Query", test_5_pdf_processing),
        ("PDF - Streaming Financial", test_6_pdf_streaming),
        ("PDF - Table Extraction", test_7_pdf_table_extraction),
        ("PDF - Year-Specific Query", test_8_pdf_year_specific),
    ]
    
    results = {}
    for name, test_func in tests:
        try:
            results[name] = test_func()
            time.sleep(1)  # Brief pause between tests
        except KeyboardInterrupt:
            print("\n\n✗ Tests interrupted by user")
            break
        except Exception as e:
            print(f"\n✗ Unexpected error in {name}: {e}")
            results[name] = False
    
    # Summary
    print("\n" + "#"*60)
    print("# TEST SUMMARY")
    print("#"*60)
    
    passed = sum(1 for v in results.values() if v)
    total = len(results)
    
    for name, result in results.items():
        status = "✓ PASS" if result else "✗ FAIL"
        print(f"{status}: {name}")
    
    print(f"\nTotal: {passed}/{total} tests passed")
    
    if passed == total:
        print("\n🎉 All tests passed!")
    else:
        print(f"\n⚠️  {total - passed} test(s) failed")
    
    print("\n💡 Tip: Edit QUESTIONS at top of file to test your specific queries")

if __name__ == "__main__":
    main()
